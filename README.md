### Hi there ðŸ‘‹

<!--
**prachi2023/prachi2023** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
-->
I am final year undergraduate student at National University of Singapore (NUS), pursuing a double degree in Computer Engineering and Business. I am a motivated, leadership-oriented student with the ability to grasp concepts quickly, a keen eye for detail, and the ability to work within aggressive timelines, with a strong passion for Machine Learning (ML), Artifical Intelligence (AI) and Data Analytics. 


<!-- - ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ”­ Iâ€™m currently working on [NotUS, a Command Line Application that makes use of software engineering principles] (https://github.com/AY2021S1-CS2113-T13-1/tp)
- ðŸŒ± Iâ€™m currently learning about Real Time Operating Systems and Data Analytics 
Here are some ideas to get you started:
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: 
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

## Past Projects 
1.<b> Augmented Laser Tag: </b>  Augmented Reality Laser Tag Game. Each player gets a gun, vest, and glove. On the glove, there are 2 sensors, an Accelerometer and a Gyroscope. Using the sensors on the glove, the aim is to detect one of 9 possible moves that the player can do. The CNN model trained is implemented in Vitis HLS, C++ to be realized on an FPGA board to improve the speed of inference during gameplay. CNN model was modeled in Python with the use of Keras </br>
2.<b> Image Captioning Project: </b> Machine Learning project that aims to generate a description for a given image, to help the visually impaired understand their surroundings better. Implemented Faster â€“ RCNN by using VGG16 to extract features from input images. Generating anchor boxes and filtering them using NMS to understand the objects in the image. Applied NLP techniques to generate the caption of the images. Modeled in Python with the use of TensorFlow and PyTorch </br>
3.<b> AI Retina Glaucoma Test: </b> Supervised Machine Learning to distinguish images of retinas with and without glaucoma </br>
4.<b> osBot:</b> A robot controlled using an android app over bluetooth. With the use of a real time operating system, the bot is able to move, flash leds, play different tunes and respond to bluetooth signal simultaneously. </br>
5.<b> Alex:</b> A robot with remote navigation, with information received from a LiDAR. Raspberry Pi was used to process the data from the LiDAR as well as send signals to control the motion of the bot. Arduino was used for the basic functionalities of the bot. </br>
<p align="center">
  <img alt="alex" src="images/alex.jpg" alt="drawing" width="200"  />
  <br><em>Figure 1</em>
</p>
6.<b> mBot:</b> Autonomous robot that used multiple sensors, including IR, sound, light and Ultrasound, to respond to multiple different audio-visual signals that determined the actions of the bot. 
<p align="center">
  <img alt="mBot" src="images/mbot.jpg" alt="drawing" width="200" />
  <br><em>Figure 1</em>
</p>
