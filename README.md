### Hi there ðŸ‘‹

<!--
**prachi2023/prachi2023** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
-->
I am currently an undergraduate student at National University of Singapore (NUS), pursuing a double degree in Computer Engineering and Business. I am a motivated, leadership-oriented student with the ability to grasp concepts quickly, a keen eye for detail, and the ability to work within aggressive timelines, with a strong passion for Machine Learning (ML), data analytics and computer vision. 


<!-- - ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ”­ Iâ€™m currently working on [NotUS, a Command Line Application that makes use of software engineering principles] (https://github.com/AY2021S1-CS2113-T13-1/tp)
- ðŸŒ± Iâ€™m currently learning about Real Time Operating Systems and Data Analytics 
Here are some ideas to get you started:
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: 
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

## Past Projects 
1.<b> Image Captioning Project: </b> Machine Learning project that aims to generate a description for a given image, to help the visually impaired understand their surroundings better. Implemented Faster â€“ RCNN by using VGG16 to extract features from input images. Generating anchor boxes and filtering them using NMS to understand the objects in the image. Applied NLP techniques to generate the caption of the images. Modelled in Python with the use of TensorFlow and PyTorch
2.<b> AI Retina Glaucoma Test: </b> Supervised Machine Learning to distinguish images of retinas with and without glaucoma 
3.<b> osBot:</b> A robot controlled using an android app over bluetooth. With the use of a real time operating system, the bot is able to move, flash leds, play different tunes and respond to bluetooth signal simultaneously. </br>
4.<b> Alex:</b> A robot with remote navigation, with information received from a LiDAR. Raspberry Pi was used to process the data from the LiDAR as well as send signals to control the motion of the bot. Arduino was used for the basic functionalities of the bot. </br>
<p align="center">
  <img alt="alex" src="images/alex.jpg" alt="drawing" width="200"  />
  <br><em>Figure 1</em>
</p>
5.<b> mBot:</b> Autonomous robot that used multiple sensors, including IR, sound, light and Ultrasound, to respond to multiple different audio-visual signals that determined the actions of the bot. 
<p align="center">
  <img alt="mBot" src="images/mbot.jpg" alt="drawing" width="200" />
  <br><em>Figure 1</em>
</p>
